services:
  bridge:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - EMBEDDING_BACKEND=${EMBEDDING_BACKEND:-local}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_OUTPUT_DIM=1536
      - EMBED_DIM=1536
      - ADMIN_TOKEN=${ADMIN_TOKEN}
      - AUTO_BOOTSTRAP=1
      # Log optimization settings
      - HA_RAG_LOG_LEVEL=TRACKING
      - HA_RAG_DETAILED_ERRORS=true
      - LOG_LEVEL=INFO
    command:
      - /bin/sh
      - -c
      - |
        ha-rag-bootstrap && \
        uvicorn app.main:app \
          --host 0.0.0.0 --port 8000 \
          --log-config docker/uvicorn_log.ini
    env_file:
      - .env
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    volumes:
      - ./litellm_config_phase3.yaml:/app/config.yaml
      - ./litellm_ha_rag_hooks_phase3.py:/app/litellm_ha_rag_hooks_phase3.py
    command: ["--config", "/app/config.yaml", "--detailed_debug"]
    environment:
      - HA_RAG_API_URL=http://bridge:8000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      # Log control for LiteLLM
      - LITELLM_LOG_LEVEL=INFO
      - LOG_PROMPTS=true
      - LOG_RESPONSES_PREVIEW=true
    env_file:
      - .env
    depends_on:
      - bridge
