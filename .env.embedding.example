# Embedding Backend Configuration
# ===============================

# Choose embedding backend: local, openai, gemini
EMBEDDING_BACKEND=local

# Local SentenceTransformer Model Configuration
# ============================================

# Recommended models for CPU-only environment (16GB RAM VM):

# 1. FASTEST - Good for rapid prototyping and development
# SENTENCE_TRANSFORMER_MODEL="all-MiniLM-L6-v2"
# Memory: ~90MB, Dimension: 384, Speed: Very Fast

# 2. BALANCED - Current default, good multilingual support
SENTENCE_TRANSFORMER_MODEL="paraphrase-multilingual-MiniLM-L12-v2"
# Memory: ~500MB, Dimension: 384, Speed: Fast, Languages: 50+

# 3. QUALITY - Better embeddings for production
# SENTENCE_TRANSFORMER_MODEL="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
# Memory: ~1GB, Dimension: 768, Speed: Medium, Languages: 50+

# 4. ENGLISH ONLY - If you only need English
# SENTENCE_TRANSFORMER_MODEL="all-mpnet-base-v2"
# Memory: ~400MB, Dimension: 768, Speed: Medium

# CPU Thread Configuration
# =======================
# Set to number of CPU cores available to the container (default: 4)
# For your VM: you can try 6-8 threads if you have enough CPU allocation
EMBEDDING_CPU_THREADS=4

# Performance tuning options:
# - Lower threads (2-4): More stable, less CPU usage
# - Higher threads (6-8): Faster processing, more CPU usage
